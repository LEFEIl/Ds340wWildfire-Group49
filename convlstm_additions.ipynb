{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fc7b75",
   "metadata": {},
   "source": [
    "# ConvLSTM Additions for Wildfire Prediction (TensorFlow/Keras)\n",
    "\n",
    "This add-on injects a ConvLSTM2D sequence model into your existing Keras workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11583492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, numpy as np, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "print('TensorFlow', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_sliding_windows(frames, T, stride=1):\n",
    "    import numpy as np\n",
    "    N = frames.shape[0]\n",
    "    M = 1 + (N - T) // stride if N >= T else 0\n",
    "    out = np.stack([frames[i:i+T] for i in range(0, N - T + 1, stride)], axis=0) if M > 0 else np.empty((0, T) + frames.shape[1:])\n",
    "    return out\n",
    "\n",
    "def make_tf_dataset(X_seq, y, batch_size=8, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_seq, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(min(len(X_seq), 2048), reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n",
    "def conv_block(x, f, k=3, s=1, p='same', act='relu', bn=True, drop=0.0):\n",
    "    x = layers.Conv2D(f, k, strides=s, padding=p, use_bias=not bn)(x)\n",
    "    if bn: x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act)(x)\n",
    "    if drop > 0: x = layers.Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def build_convlstm_model(input_shape, num_classes, \n",
    "                         convlstm_filters=(32, 64),\n",
    "                         convlstm_kernel=3,\n",
    "                         convlstm_drop=0.1,\n",
    "                         post_cnn_filters=(64, 64),\n",
    "                         gap_drop=0.2):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, 3, padding='same', use_bias=False))(inputs)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.Activation('relu'))(x)\n",
    "    for i, f in enumerate(convlstm_filters):\n",
    "        return_seq = (i < len(convlstm_filters) - 1)\n",
    "        x = layers.ConvLSTM2D(filters=f, kernel_size=convlstm_kernel, padding='same',\n",
    "                              return_sequences=return_seq, dropout=convlstm_drop)(x)\n",
    "        if return_seq:\n",
    "            x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        else:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "    for f in post_cnn_filters:\n",
    "        x = conv_block(x, f, k=3, bn=True, drop=0.1)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if gap_drop > 0: x = layers.Dropout(gap_drop)(x)\n",
    "    if num_classes == 1:\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "        metrics = ['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy', keras.metrics.AUC(name='auc', multi_label=False)]\n",
    "    model = keras.Model(inputs, outputs, name='ConvLSTM_Wildfire')\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4665de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage (replace with real data)\n",
    "# X_train_seq = np.random.rand(32, 6, 64, 64, 6).astype('float32')\n",
    "# y_train = np.random.randint(0, 2, size=(32,)).astype('int32')\n",
    "# X_val_seq = np.random.rand(8, 6, 64, 64, 6).astype('float32')\n",
    "# y_val = np.random.randint(0, 2, size=(8,)).astype('int32')\n",
    "# ds_train = make_tf_dataset(X_train_seq, y_train, batch_size=4, shuffle=True)\n",
    "# ds_val = make_tf_dataset(X_val_seq, y_val, batch_size=4, shuffle=False)\n",
    "# model = build_convlstm_model(input_shape=X_train_seq.shape[1:], num_classes=2)\n",
    "# ckpt = ModelCheckpoint('best_convlstm.keras', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n",
    "# es = EarlyStopping(monitor='val_auc', mode='max', patience=8, restore_best_weights=True, verbose=1)\n",
    "# history = model.fit(ds_train, validation_data=ds_val, epochs=50, callbacks=[ckpt, es])\n",
    "# print('Best model saved to best_convlstm.keras')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
